{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연속 vs 카테고리 값\n",
    "- 연속값\n",
    "    - 비슷한 값이라면 서로 비슷하다는 의미를 지니지만\n",
    "- 카테고리\n",
    "    - 비슷한 값일지라도 서로 상관겂다는 의미를 지닌다.\n",
    "> 그렇기 때문에 카테고리 값을 특징 벡터로 표현할 때에 인덱스 값으로 표기하는 대신 다른 방법을 선택해야 한다. <br>\n",
    "> 만약 그대로 인덱스 값으로 표현한다면 코사인 유사도나 유클리디안 거리에서 이상한 계산이 이루어질 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원 핫 인코딩\n",
    "- 원 핫 인코딩은 크기가 의미를 갖는 정수로 나타내는 대신 한 개의 1과 n-1개의 0으로 이루어진 n차원의 벡터로 나타내는 방법을 의미한다\n",
    "- 벡터 대부분의 차원이 0인 경우를 희소벡터라고 부르고 이와 반대되는 개념을 고밀도 벡터라고 한다.\n",
    "- 희소벡터의 경우에는 유사도 계산이나 거리 계산을 통해 샘플 사이의 관계를 파악하는데 어려움을 겪을 수 있다.\n",
    "- 또한 원 핫 벡터는 희소 벡터의 정점이라고 볼 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 임베딩\n",
    "- 자연어 처리는 단어를 데이터로 다루는 대표적인 분야이다.\n",
    "- 따라서 단어를 모델에 입력으로 넣어주기 위해서 어쩔 수 없이 원핫인코딩 벡터를 활용해야 한다.\n",
    "- 하지만 단어의 개수는 몇 만개 수준으로 매우 많기 땜누에 차원이 커져서 비효울적이며 원 핫 인코딩을 통해서는 단어 사이의 유사도를 표현할 수없다.\n",
    "- 이때 필요한 것이 단어 임베딩이다. 이를 통해서 단어를 고밀도 벡터로 표현할 수 있게 된다. 그러면 단어들은 서로 비슷한 단어끼리 비슷한 값ㅇ르 지닌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67a89c197df658fa9381c6ce748d39d138b8172be5d6bcdac46c5a692d7ae1fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
