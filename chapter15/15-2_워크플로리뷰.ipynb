{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 워크플로 리뷰\n",
    "- 문제정의\n",
    "    - 단계를 나누고 simplify\n",
    "    - x와 y를 정의\n",
    "- 데이터 수집\n",
    "    - 문제 정의에 따른 수집\n",
    "    - 필요에 따라 레이블링\n",
    "- 데이터 전처리 및 분석\n",
    "    - 형태를 가공\n",
    "    - 필요에 따라 EDA 수행\n",
    "- 알고리즘 적용\n",
    "    - 가설을 세우고 구현/적용\n",
    "- 평가\n",
    "    - 실험 설계\n",
    "    - 데이터셋 구송\n",
    "- 배포\n",
    "    - RESTful API를 통한 배포\n",
    "    - 상황에 따라 유지/보수"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 정의\n",
    "- 우리는 손글씨 숫자를 인식하는 함수 f*를 근사계산하고 싶다.\n",
    "- 따라서 근사계산한 모델함수는 이미지를 입력받아 숫자 레이블을 출력하도록 구성될 것이다.\n",
    "- 이 모델을 만들기 위해 손글씨 숫자를 수집하고 이에 대한 레이블링도 수행한다.\n",
    "- 이렇게 데이터셋 구축 작업을 수행한 것이 ㅂ로 MNIST 데이터셋이다.\n",
    "- 이미지는 28 X 28개의 256단계 흑백 픽셀로 구성되어 있다.\n",
    "- 따라서 만들 함수의 입력은 784차원 백터가 되고 출력은 각 숫자 클래스별 확률 값이 되도록 구현하는 일이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집\n",
    "- 실무에서는 직접 데이터 수집 및 레이블링을 진행하거나 외주를 맡기거나 단기 계약직 등을 고용하느 방법이 있다.\n",
    "- 둘 중 어떤 선택을 하든지 업므의 크기를 산정해야 하고 예산을 준비하는 작업도 필요하다.\n",
    "- 데이터 수집이 완료된상태에서의 레이블링\n",
    "     - MNIST 데이터셋과 같이 70,000장의 손글씨에 대한 레이블링을 진행해야 한다.\n",
    "     - 먼저 파일이 이름 순서대로 정렬되어 있을 때 파일 이름과 이에 대한 레이블을 적을 수 있도록 엑셀 파일을 준비한다.\n",
    "     - 그럼 차례대로 그림을 띄우면서 엑셀 시트에 정답 레블링을 깅ㅂ해야할 것이다.\n",
    "     - 팀원 3명이면 대략 4일 정도 걸릴 것이다.\n",
    "- 개념 증명 과정을 거쳐서 실현 가능성을 확인한 후에 본격적인 자원을 투입하는 것이 훨씬 바람직하다\n",
    "- 이때 보통 프로토타입 모델은 실제 서비스 또는 배포를 위한 모델인 만큼 대단히 뛰어날 필요없이 다만 데이터셋이 수집되었을 때의 가능성만 증명할 수 있으면 된다.\n",
    "- 7만장 다 모을 필요 없고 1만장 정도면 충분하기도 하다.\n",
    "- 개념 증명이 완료된 이후에 이를 바탕으로 예산을 확보하고 외주를 맡기는 등의 작업 진행 방향이 바람직할 것이다.\n",
    "- 외주를 맡길 경우의 견적\n",
    "    - 보통 작업의 난이도에 따라서 샘플당 몇 십원에서 많게는 몇 백 원까지 책정된다.\n",
    "    - 이외에도 비용과 노력이 필요하다\n",
    "    - 직원이 직접 수행한 것이 아니다 보니 레이블링의 정확도나 품질이 떨어질 수 있다.\n",
    "    - 따라서 레이블링 결과물의 품질을 관리하는 업무가 수반되어야 한다.\n",
    "    - 즉, 외부에 작업을 맡기더라도 데이터 수집에 대해 마냥 손을 놓을 수는 없다는 말이다.\n",
    "    - 따라서 데이터 수집 업무를 수애할 때 이러한 점을 모두 고려해야 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "- 총 7만장 중 train : 48,000 / val : 12,000 / test : 10,000이 있다.\n",
    "- 이렇게 데이터를 분할한 이후에 데이터 전처리를 수행한다.\n",
    "- 이때 데이터의 성격에 따라 필요한 전처리가 매우 다르다.\n",
    "- 그렇기에 전처리 이전에 데이터가 어떤 분포와 형태를 띠고 있는지 면밀히 분석해야 한다.\n",
    "- 다양한 전처리들은 데이터의 종류와 형태 그리고 상태에 따라서 다르게 적용되며 크게 다음과 같이 나눌 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/preprocess.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일부 전처리 기법드은 데이터를 기반으로 파라미터가 결정된다. \n",
    "- 예를 들어 정규화 스케일은 평균과 표준편차를 계산하여 표준정규분포 형태로 반환하는 것인데 당연히 평균과 표준편차는 데이터로부터 계산되어야 한다.\n",
    "- 이러한 평균과 표준편차 계산과 같은 데이터 기반의 전처리 기법은 학습 데이터셋 기준으로 수행되어야 한다.\n",
    "- 즉 학습 데이터만 가지고 평균과 표준편차를 계산한 뒤 학습/검증/테스트 데이터셋에 일괄 적용하는 형태가 되어야 한다.\n",
    "- 전처리는 학습/검증/테스트 데이터셋 분할 작업 이후에 수행하는 것이 바람직하다.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 알고리즘 적용\n",
    "- 데이터의 분포나 성질의 분석한 결과를 바탕으로 알맞은 가설을 선정하고 알고리즘 구현 및 적용해야한다.\n",
    "- 이 과정에서 꼭 심층신경망이 적용될 필요는 없고 분석 결과에 따라 가장 적절한 머신러닝 알고리즘을 적용함녀 된다.\n",
    "- 만약 심층신경망을 적용하기로 결정했다면 다음 그림과 같이 신경망의 구조를 결정하는 작업을 생각해 볼 수 있다.\n",
    "- ![](../img/%EC%8B%A0%EA%B2%BD%EB%A7%9D%EA%B2%B0%EC%A0%95.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음은 하이퍼파라미터 결정 과정입니다.\n",
    "- ![](../img/hp%EA%B2%B0%EC%A0%95.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하이퍼파라미터를 수정하며 이 과정을 반복하여 모델의 성능을 점진적으로 개선한다.\n",
    "- 도는 단순한 하이퍼파라미터 수정만으로도 충분한 성능 개선이 이루어지지 않는다면 성능 저하 문제의 원인에 대한 적절한 가설을 설정하고 모델의 구조를 바꾸는 등 수정을 거쳐 성능을 개선할 수도 있어야 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가\n",
    "- 공정하고 객관적인 평가가 이루어져야 한다.\n",
    "- 언더피팅이 의심될 경우에는 모델의 수용 능력을 더 키우는 방향으로 하이퍼파라미터를 튜닝\n",
    "- 오버피팅으로 인해 일반화 성능이 저하되는 것이 우려될 때에는 정규화 기법ㅇ르 강화하는 방향으로 튜닝하면서 학습과 평가를 반복 수행하게 될 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/orverfiting.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 성능 개선 작업이 종료되고 나면 테스트 데이터셋을 활용하여 평가를 수행함으로써 진정한 모델의 성능을 공정하게 평가할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배포\n",
    "- 실전에 투입될 준비가 되었다고 판단되면 본격적으로 배포 과정에 들어가게 된다.\n",
    "- 이번 실습에서는 배포를 위한 추론 코드는 손쉬운 시각화를 위해 주피터 노트북을 통해 구현\n",
    "- 주피터 노트북에 함수 형태로 긴으별로 나누어 잘 구현함녀 실무 환경에서는 이 함수들을 별도의 스크립트 파일에 구현하는 형태로 활용할 수 있을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c76801ef4636d259bef71178ff9b6783756e10e36adbdb1b3ea353d89da04bd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
