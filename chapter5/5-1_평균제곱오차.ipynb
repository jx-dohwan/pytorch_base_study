{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평균 제곱 오차\n",
    "- 우리가 가지고 있는 모델을 통해 알 수 없는 함수 f*를 근사계산을 하는데, 이 근사계산을 잘 하고 있는지 판단해야한다.\n",
    "- 가장 간단한 방법은 해당 모델에 수집한 데이터로 입력을 넣었을 때 원하는 출력이 나오는지 확인하는 것이다.\n",
    "- 원하는 출력값과 모델이 반환한 출력값을 비교해서 차이가 적을수록 좋은 모델일 것이다. 이 차이를 손실(loss)값이라고 부른다.\n",
    "- 즉, 손실 값이 작을수록 해댱 모델은 근사계산하고자하는 함수 f*를 잘 근사계산하고 있다고 판단할 수 있다.\n",
    "- 손실함수\n",
    "    - 모델의 가중치 파라미터가 바뀌면 손실값이 바뀌기 때문에 가중치 파라미터를 함수 입력으로 주고 손실 값을 출력으로 반환하도록 \n",
    "    - 손실 함수의 출력값(손실 값)을 최소로 만드는 모델의 가중치 파라미터 집합(함수 입력값)를 찾기만 하면 된다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실 함수 선택\n",
    "- 손실 값의 정의는 타깃 출력과 모델의 출력간의 차이 크기의 합이라고 했다. \n",
    "- 이 때 차이의 크기를 정의하는 방법은 다양한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 norm\n",
    "- n차원 벡터의 각 요소들 사이의 차이에 대한 절댓값을 모두 더한 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 norm\n",
    "- 유클리디안 거리(Euclidean distance)로도 잘 알려져 있는데 두 점 사이의 거리를 계산하는 방법\n",
    "- 따라서 손실 함수에 L2 norm을 잘 활용하면 정답과 모델 출력 사이의 거리를 최소화 한다고 볼 수 있다.\n",
    "- L2 norm은 벡터의 각 요소들 간 차이에 대해 제곱을 구하여 모두 더한 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE\n",
    "- 제곱근 평균 제곱 오차(Root Mean Squared Error)는 앞서 살펴본 L2 norm과 매우 유사한 수식을 갖고 있다.\n",
    "- 다만 제곱근을 구하기 전에 벡터의 차원 크기인 n으로 나누어 편균을 취하는 거승ㄹ 볼 수 있다.\n",
    "- 즉, 오차에 제곱을 구하고 평균을 취해서 제곱근을 씌워주주는 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE\n",
    "- 평균 제곱 오차(Mean Squared Error)이다. \n",
    "- RMSE에 제곱을 취한 것과 같다.  \n",
    "- 따라서 훨씬 쿤 차이 값을 반환하게 된다.\n",
    "- MSE는 L2 norm의 제곱에 상수를 곱한 값이다. 그래서 MSE와 L2 norm의 제곱을 혼용하여 표기합니다.\n",
    "- N개의 데이터 샘플에 대한 손실 값은 각 샘플의 타깃 출력값 m차원의 벡터와 모델의 출력값 m차원의 벡터 사이의 MSE에 대한 합으로 정의된다.\n",
    "- 경우에 따라 샘플의 숫자 N을 추가적으로 나누어 샘플들의 MSE에 대한 평균을 취하기도 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x_hat, x):\n",
    "    y = ((x-x_hat)**2).mean()\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.FloatTensor([[1,1],[2,2]])\n",
    "x_hat = torch.FloatTensor([[0,0],[0,0]])\n",
    "print(mse(x_hat, x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.functional 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.mse_loss(x_hat,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(x_hat, x, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [4., 4.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(x_hat, x, reduction='none')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn사용하기\n",
    "- 위의 방법과의 차이는 거의 없다.\n",
    "- 하지만 이 방법을 사용하게 되면 nn.Module의 하위 클래스 내부에 선언하기 때문에 계층의 하나처럼 취급할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "mse_loss = nn.MSELoss()\n",
    "mse_loss(x_hat, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c76801ef4636d259bef71178ff9b6783756e10e36adbdb1b3ea353d89da04bd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
