{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE(Maximum Likelihood Estimation)\n",
    "- 딥러닝이 학습되는 원리인 최대 가능도 방법에 대해서 알아보도록 하겠다.\n",
    "- 확률 분포의 형태를 정의하는 값을 분포의 파라미터라고 부른다.\n",
    "- 주어진 샘플에 임의의 파라미터를 적용하여 정규분포를 만들어본다.\n",
    "- 만들어진 정규 분포가 적절하다면 주어진 샘플들이 만들어진 분포 위에서 높은 확률을 지녀야 한다. \n",
    "- 따라서 샘플 위의 점섬들의 길이가 최대가 되었으면 한다.\n",
    "- 그 다음 임의의 파라미터를 적용하여 또 다른 분포를 만들어 본다.\n",
    "- 마지막으로 또 다른 임의의 파라미터를 적용하여 분포를 만들어본다.\n",
    "- 그럼 앞에서 만들어본 두 정규 분포보다 이 분포에 따른 점선의 길이가 훨씬 긴 것을 볼 수 있다.\n",
    "- 이때 점선의 길이를 가능도라고 한다.\n",
    "- 결과적으로 우리는 이 점섬 길이들의 곱인 가능도를 쵀대로 하는 분포의 파라미터를 찾아내려던 것인이 이 과정을 최대 가능도 방법이라고 부른다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 가능도는 현재 분포의 파라미터가 수집된 데이터를 얼마나 잘 설명하는지 나타내는 점수라고 불 수 있다. 가능도 함수는 분포의 파라미터의 변화에 따라 변화하는 가능도를 나타낸 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로그 가능도\n",
    "- 가능도는 확률의 곱으로 표현된다. 따라서 샘플의 숫자가 많아진다면 가능도의 크기는 굉장히 작아질 가능성이 높다.\n",
    "- 그렇다면 이것을 계산할 때 언더플로에 빠질 가능성이 높다.\n",
    "- 이때 로그를 도입하여 확률의 곱셈을 덧셉으로 바꿀 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사상승법을 통한MLE\n",
    "- 경사상승법을 활용하여 손쉽게 MLE를 수행할 수 있다.\n",
    "- 경사상승법을 통해 가능도 함수를 최대화하는 파라미터를 찾아볼 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67a89c197df658fa9381c6ce748d39d138b8172be5d6bcdac46c5a692d7ae1fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
