{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.FloatTensor([[.1, .2, .3],\n",
    "                            [.3,.4,.5],\n",
    "                            [.7, .8, .9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1550, 0.8439, 0.7339],\n",
      "        [0.8652, 0.5077, 0.3989],\n",
      "        [0.0263, 0.4722, 0.7065]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand_like(target)\n",
    "x.requires_grad = True\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1718, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.mse_loss(x, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th Loss : 1.0391e-01\n",
      "tensor([[0.1428, 0.7008, 0.6375],\n",
      "        [0.7396, 0.4838, 0.4213],\n",
      "        [0.1760, 0.5450, 0.7495]], requires_grad=True)\n",
      "2-th Loss : 6.2862e-02\n",
      "tensor([[0.1333, 0.5895, 0.5625],\n",
      "        [0.6419, 0.4651, 0.4388],\n",
      "        [0.2925, 0.6017, 0.7830]], requires_grad=True)\n",
      "3-th Loss : 3.8027e-02\n",
      "tensor([[0.1259, 0.5030, 0.5042],\n",
      "        [0.5659, 0.4507, 0.4524],\n",
      "        [0.3830, 0.6457, 0.8090]], requires_grad=True)\n",
      "4-th Loss : 2.3004e-02\n",
      "tensor([[0.1201, 0.4356, 0.4588],\n",
      "        [0.5068, 0.4394, 0.4630],\n",
      "        [0.4535, 0.6800, 0.8292]], requires_grad=True)\n",
      "5-th Loss : 1.3916e-02\n",
      "tensor([[0.1156, 0.3833, 0.4235],\n",
      "        [0.4609, 0.4307, 0.4712],\n",
      "        [0.5083, 0.7067, 0.8449]], requires_grad=True)\n",
      "6-th Loss : 8.4184e-03\n",
      "tensor([[0.1122, 0.3426, 0.3961],\n",
      "        [0.4251, 0.4238, 0.4776],\n",
      "        [0.5509, 0.7274, 0.8572]], requires_grad=True)\n",
      "7-th Loss : 5.0926e-03\n",
      "tensor([[0.1095, 0.3109, 0.3747],\n",
      "        [0.3973, 0.4185, 0.4826],\n",
      "        [0.5840, 0.7436, 0.8667]], requires_grad=True)\n",
      "8-th Loss : 3.0807e-03\n",
      "tensor([[0.1074, 0.2862, 0.3581],\n",
      "        [0.3757, 0.4144, 0.4865],\n",
      "        [0.6098, 0.7561, 0.8741]], requires_grad=True)\n",
      "9-th Loss : 1.8636e-03\n",
      "tensor([[0.1057, 0.2671, 0.3452],\n",
      "        [0.3589, 0.4112, 0.4895],\n",
      "        [0.6298, 0.7659, 0.8798]], requires_grad=True)\n",
      "10-th Loss : 1.1274e-03\n",
      "tensor([[0.1045, 0.2522, 0.3352],\n",
      "        [0.3458, 0.4087, 0.4918],\n",
      "        [0.6454, 0.7734, 0.8843]], requires_grad=True)\n",
      "11-th Loss : 6.8200e-04\n",
      "tensor([[0.1035, 0.2406, 0.3273],\n",
      "        [0.3356, 0.4068, 0.4936],\n",
      "        [0.6576, 0.7793, 0.8878]], requires_grad=True)\n",
      "12-th Loss : 4.1257e-04\n",
      "tensor([[0.1027, 0.2316, 0.3213],\n",
      "        [0.3277, 0.4053, 0.4950],\n",
      "        [0.6670, 0.7839, 0.8905]], requires_grad=True)\n",
      "13-th Loss : 2.4958e-04\n",
      "tensor([[0.1021, 0.2245, 0.3165],\n",
      "        [0.3215, 0.4041, 0.4961],\n",
      "        [0.6743, 0.7875, 0.8926]], requires_grad=True)\n",
      "14-th Loss : 1.5098e-04\n",
      "tensor([[0.1016, 0.2191, 0.3129],\n",
      "        [0.3168, 0.4032, 0.4970],\n",
      "        [0.6800, 0.7903, 0.8943]], requires_grad=True)\n",
      "15-th Loss : 9.1333e-05\n",
      "tensor([[0.1013, 0.2148, 0.3100],\n",
      "        [0.3130, 0.4025, 0.4977],\n",
      "        [0.6845, 0.7924, 0.8955]], requires_grad=True)\n",
      "16-th Loss : 5.5251e-05\n",
      "tensor([[0.1010, 0.2115, 0.3078],\n",
      "        [0.3101, 0.4019, 0.4982],\n",
      "        [0.6879, 0.7941, 0.8965]], requires_grad=True)\n",
      "17-th Loss : 3.3423e-05\n",
      "tensor([[0.1008, 0.2090, 0.3061],\n",
      "        [0.3079, 0.4015, 0.4986],\n",
      "        [0.6906, 0.7954, 0.8973]], requires_grad=True)\n",
      "18-th Loss : 2.0219e-05\n",
      "tensor([[0.1006, 0.2070, 0.3047],\n",
      "        [0.3061, 0.4012, 0.4989],\n",
      "        [0.6927, 0.7964, 0.8979]], requires_grad=True)\n",
      "19-th Loss : 1.2231e-05\n",
      "tensor([[0.1005, 0.2054, 0.3037],\n",
      "        [0.3048, 0.4009, 0.4991],\n",
      "        [0.6943, 0.7972, 0.8984]], requires_grad=True)\n",
      "20-th Loss : 7.3992e-06\n",
      "tensor([[0.1004, 0.2042, 0.3028],\n",
      "        [0.3037, 0.4007, 0.4993],\n",
      "        [0.6956, 0.7978, 0.8987]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "threshold = 1e-5\n",
    "learning_rate = 1.\n",
    "iter_cnt = 0\n",
    "\n",
    "while loss > threshold:\n",
    "    iter_cnt += 1\n",
    "    loss.backward() # 편미분을 수행함 x.grad에 자동저장됨\n",
    "    # backward를 호출하기 위한 텐서의 크기는 스칼라여야한다. 스칼라가 아닌경우 파이토치는 오류를 발생시킨다.\n",
    "\n",
    "    x = x - learning_rate * x.grad # 경사하강법 수행\n",
    "\n",
    "    x.detach_()\n",
    "    x.requires_grad_(True)\n",
    "\n",
    "    loss = F.mse_loss(x, target)\n",
    "\n",
    "    print(\"%d-th Loss : %.4e\" % (iter_cnt, loss))\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c76801ef4636d259bef71178ff9b6783756e10e36adbdb1b3ea353d89da04bd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
