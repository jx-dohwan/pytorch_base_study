{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 심층신경망의 학습 개요\n",
    "- 심층신경망을 구성하는 여러 계층의 가중치 파라미터들로 손실 함수를 미분하고\n",
    "- 그 결과를 경사하강법에 활용하여 각 가중치 파라미터를 업데이트 한다.\n",
    "- 기존의 선형 회귀와 비교하면 선형 계층 하나로 구성됐던 모델이 심층 신경망으로 바뀌었을 뿐이다. \n",
    "- 문제는 가중치 파라미터가 늘어나게 되어 손실함수에 대해 미분을 해야하는 일이 늘어나고\n",
    "- 더 큰 문제는 입력으로부터 가까운 계층의 파라미터이다. 훨씬 복잡한 함수 꼴이 된다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 역전파\n",
    "- 역전파(back-propgation)알고리즘을 통해 효율적으로 심층신경망을 학습시킬 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 체인 룰(chain rule)\n",
    "- 역전파 알고리즘은 체인룰을 통해 구현된다.\n",
    "- y를 x로 미분하는 작업은 체인룰에 의해서 y를 h로 미분한 값에 h를 x로 미분한 값을 곱하는 것과 같아진다.\n",
    "- 심층 신경망도 여러 계층이 쌓여서 만들어진 합성함수이기 때문에 심층 신경망의 미분도 간단한 수식에 대한 미분의 곱으로 표현될 수 있다.\n",
    "- 심지어 간단한 수식드렝 대한 미분은 다른 게층의 미분을 구할 때 다시 재활용할 수 있어 훨씬 효율적인 계산이 가능해진다.\n",
    "- 결론적으로 미분 계산 과정이 계속해서 뒤 쪽 계층으로 전달되는 것처럼 보이며 이를 역전파라고 한다.\n",
    "> 역전파 알고리즘을 통해 훨씬 효율적인 미분 게산을 할수 있게 되어 부담 없이 깊은 심층 신경망을 구성할 수 있게 되었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c76801ef4636d259bef71178ff9b6783756e10e36adbdb1b3ea353d89da04bd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
